{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/041_attention/attention.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kzp2jHl3qY7"
      },
      "source": [
        "# Mecanismos de Atenci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv20V-KqDhH6"
      },
      "source": [
        "En el [post](https://sensioai.com/blog/040_encoder_decoder) anterior aprendimos a implementar una arquitectura de red neuronal conocida como `seq2seq`, que utiliza dos redes neuronales (el `encoder` y el `decoder`) para poder trabajar con secuencias de longitud arbitraria tanto a sus entradas como en las salidas. Este modelo nos permite llevar a cabo tareas tales como la traducci√≥n de texto entre dos idiomas, resumir un texto, responder preguntas, etc.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "Si bien este modelo nos dio buenos resultados, podemos mejorarlo. Si prestamos atenci√≥n a la arquitectura que desarrollamos, el `decoder` (encargado de generar la secuencia de salida) es inicializado con el √∫ltimo estado oculto del `encoder`, el cual tiene la responsabilidad de codificar el significado de toda la frase original. Esto puede ser complicado, sobre todo al trabajar con secuencias muy largas, y para solventar este problema podemos utilizar un mecanismo de `atenci√≥n` que no solo reciba el √∫ltimo estado oculto si no tambi√©n tenga acceso a todas las salidas del `encoder` de manera que el `decoder` sea capaz de \"focalizar su atenci√≥n\" en aquellas partes m√°s importantes. Por ejemplo, para traducir la primera palabra es l√≥gico pensar que lo m√°s importante ser√° la primera palabra y sus adyacentes en la frase original, pero usar el √∫ltimo estado oculto del `encoder` puede no ser suficiente para mantener estas relaciones a largo plazo. Permitir al `decoder` acceder a esta informaci√≥n puede resultar en mejores prestaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFyd0UgDhH7"
      },
      "source": [
        "> üí° En la pr√°ctica, los mecanismos de atenci√≥n dan muy buenos resultados en tareas que envuelvan datos secuenciales (como aplicaciones de lenguaje). De hecho, los mejores modelos a d√≠a de hoy para tareas de `NLP` no est√°n basados en redes recurrentes sino en arquitecturas que √∫nicamente implementan mecanismos de atenci√≥n en varias capas. Estas redes neuronales son conocidas como `Transformers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtdizuVTDhH7"
      },
      "source": [
        "## El *dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-03T08:31:48.390280Z",
          "start_time": "2020-09-03T08:31:48.382280Z"
        },
        "id": "daTZSHr8DhH8"
      },
      "source": [
        "Vamos a resolver exactamente el mismo caso que en el post anterior, as√≠ que todo lo que hace referencia al procesado de datos lo dejaremos igual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:52.733066Z",
          "start_time": "2020-09-04T12:31:52.725066Z"
        },
        "id": "jjx2B4Q3DhH8"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def read_file(file, reverse=False):\n",
        "    # Read the file and split into lines\n",
        "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.056055Z",
          "start_time": "2020-09-04T12:31:52.735065Z"
        },
        "id": "iuI67myQDhH-"
      },
      "source": [
        "pairs = read_file('deu.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.071561Z",
          "start_time": "2020-09-04T12:31:56.058156Z"
        },
        "id": "onkJ27fWDhH-",
        "outputId": "077999c1-13e4-4f3b-ad00-abda4c5fcf50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "\n",
        "random.choice(pairs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is this for me ?', 'ist das fur mich ?']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.087569Z",
          "start_time": "2020-09-04T12:31:56.074570Z"
        },
        "id": "nlP5chOyDhH_"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n",
        "        self.n_words = 3  # Count SOS, EOS and PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def indexesFromSentence(self, sentence):\n",
        "        return [self.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "    def sentenceFromIndex(self, index):\n",
        "        return [self.index2word[ix] for ix in index]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFa0Pg3mDhIA"
      },
      "source": [
        "Para poder aplicar la capa de `attention` necesitamos que nuestras frases tengan una longitud m√°xima definida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:56.103564Z",
          "start_time": "2020-09-04T12:31:56.088570Z"
        },
        "id": "bqBjVo-fDhIA"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPairs(pairs, filters, lang=0):\n",
        "    return [p for p in pairs if p[lang].startswith(filters)]\n",
        "\n",
        "def trimPairs(pairs):\n",
        "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.717657Z",
          "start_time": "2020-09-04T12:31:56.104565Z"
        },
        "code_folding": [
          0
        ],
        "id": "p0xlL2RpDhIB",
        "outputId": "8c664201-6e49-4351-cb41-f6f969eda9e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def prepareData(file, filters=None, reverse=False):\n",
        "\n",
        "    pairs = read_file(file, reverse)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
        "\n",
        "    if filters is not None:\n",
        "        pairs = filterPairs(pairs, filters, int(reverse))\n",
        "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
        "\n",
        "    pairs = trimPairs(pairs)\n",
        "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang('eng')\n",
        "        output_lang = Lang('deu')\n",
        "    else:\n",
        "        input_lang = Lang('deu')\n",
        "        output_lang = Lang('eng')\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "        # add <eos> token\n",
        "        pair[0] += \" EOS\"\n",
        "        pair[1] += \" EOS\"\n",
        "\n",
        "    print(\"Longitud vocabularios:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('deu.txt')\n",
        "\n",
        "# descomentar para usar el dataset filtrado\n",
        "#input_lang, output_lang, pairs = prepareData('spa.txt', filters=eng_prefixes)\n",
        "\n",
        "random.choice(pairs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 145759 pares de frases\n",
            "Tenemos 144112 pares de frases con longitud menor de 10\n",
            "Longitud vocabularios:\n",
            "deu 10552\n",
            "eng 19777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats are natural born hunters . EOS', 'katzen sind geborene jager . EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.730653Z",
          "start_time": "2020-09-04T12:31:59.719659Z"
        },
        "scrolled": true,
        "id": "4adczw9qDhIB",
        "outputId": "acbe81bf-42e8-44e2-9e4a-13670b63252d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output_lang.indexesFromSentence('ich bin so durstig .')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36, 92, 604, 1491, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:31:59.754653Z",
          "start_time": "2020-09-04T12:31:59.731654Z"
        },
        "id": "tKV0Hk3JDhIC",
        "outputId": "3ef47a42-c036-409c-dd04-a9ac3465a805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output_lang.sentenceFromIndex([3, 1028, 647, 5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['geh', 'stark', 'blind', 'hallo']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g6d3FnUDhIC"
      },
      "source": [
        "En el `Dataset` nos aseguraremos de a√±adir el *padding* necesario para que todas las frases tengan la misma longitud, lo cual no hace necesario utilizar la funci√≥n `collate` que implementamos en el post anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:00.233655Z",
          "start_time": "2020-09-04T12:31:59.756655Z"
        },
        "code_folding": [],
        "id": "zi3oPVr7DhIC",
        "outputId": "02942f67-25fb-4101-815a-595b2ed6ba4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_lang, output_lang, pairs, max_length):\n",
        "        self.input_lang = input_lang\n",
        "        self.output_lang = output_lang\n",
        "        self.pairs = pairs\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        inputs = torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long)\n",
        "        outputs = torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n",
        "        # metemos padding a todas las frases hast a la longitud m√°xima\n",
        "        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.input_lang.word2index['PAD']), \\\n",
        "            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.output_lang.word2index['PAD'])\n",
        "\n",
        "# separamos datos en train-test\n",
        "train_size = len(pairs) * 80 // 100\n",
        "train = pairs[:train_size]\n",
        "test = pairs[train_size:]\n",
        "\n",
        "dataset = {\n",
        "    'train': Dataset(input_lang, output_lang, train, max_length=MAX_LENGTH),\n",
        "    'test': Dataset(input_lang, output_lang, test, max_length=MAX_LENGTH)\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['test'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115289, 28823)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.359235Z",
          "start_time": "2020-09-04T12:32:00.234660Z"
        },
        "id": "NI-4eXBzDhID",
        "outputId": "27965bb7-3d6c-46db-dd53-44fdc8f02d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_sentence, output_sentence = dataset['train'][1]\n",
        "\n",
        "input_sentence, output_sentence"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 4, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
              " tensor([5, 6, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.374232Z",
          "start_time": "2020-09-04T12:32:01.360239Z"
        },
        "id": "bkC8KTkXDhID",
        "outputId": "94557a8c-ba66-4c16-d140-95e5cce66ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['hi', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['hallo', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.405231Z",
          "start_time": "2020-09-04T12:32:01.375236Z"
        },
        "id": "cSMTf916DhID",
        "outputId": "2196c167-72b1-477e-cd6e-241dde829310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False),\n",
        "}\n",
        "\n",
        "inputs, outputs = next(iter(dataloader['train']))\n",
        "inputs.shape, outputs.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 10]), torch.Size([64, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T08:13:53.670033Z",
          "start_time": "2020-09-04T08:13:53.652976Z"
        },
        "id": "blqqT_eRDhIE"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkdKVyp7DhIE"
      },
      "source": [
        "En lo que se refiere al `encoder`, seguimos usando exactamente la misma arquitectura. La √∫nica diferencia es que, adem√°s del √∫ltimo estado oculto, necesitaremos todas sus salidas para que el `decoder` pueda usarlas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.421231Z",
          "start_time": "2020-09-04T12:32:01.406231Z"
        },
        "id": "ltJt9863DhIE"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, input_sentences):\n",
        "        embedded = self.embedding(input_sentences)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.452231Z",
          "start_time": "2020-09-04T12:32:01.422235Z"
        },
        "id": "xNp_995_DhIE",
        "outputId": "b28e383d-48ba-4d3e-9f58-281258ecb0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder = Encoder(input_size=input_lang.n_words)\n",
        "encoder_outputs, encoder_hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n",
        "\n",
        "# [batch size, seq len, hidden size]\n",
        "encoder_outputs.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.468231Z",
          "start_time": "2020-09-04T12:32:01.453237Z"
        },
        "id": "IJPUWzuuDhIF",
        "outputId": "9d4dba8c-a5cc-4e18-c96f-3cce90cdcbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "encoder_hidden.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do1BYr7iDhIF"
      },
      "source": [
        "### El *decoder* con *attention*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbSny1MIDhIF"
      },
      "source": [
        "Vamos a ver un ejemplo de implementaci√≥n de una capa de atenci√≥n para nuestro `decoder`. En primer lugar tendremos una capa lineal que recibir√° como entradas los `embeddings` y el estado oculto anterior (concatenados). Esta capa lineal nos dar√° a la salida tantos valores como elementos tengamos en nuestras secuencias de entrada (recuerda que las hemos forzado a tener una longitud determinada). Despu√©s, aplicaremos una funci√≥n `softmax` sobre estos valores obteniendo as√≠ una distribuci√≥n de probabilidad que, seguidamente, multiplicaremos por los *outputs* del encoder (que tambi√©n tienen la misma longitud). En esta funci√≥n de probabilidad, cada elemento tiene un valor entre 0 y 1. As√≠ pues, esta operaci√≥n dar√° m√°s importancia a aquellos *outputs* del `encoder` m√°s importantes mientras que al resto les asignar√° unos valores cercanos a 0. A continuaci√≥n, concatenaremos estos valores con los `embeddings`, de nuevo, y se lo daremos a una nueva capa lineal que combinar√° estos `embeddings` con los *outputs* del `encoder` re-escalados para obtener as√≠ los *inputs* finales de la capa recurrente.\n",
        "\n",
        "En resumen, usaremos las entradas y estado oculto del `decoder` para encontrar unos pesos que re-escalar√°n las salidas del `encoder`, los cuales combinaremos de nuevo con las entradas del `decoder` para obtener las representaciones finales de nuestras frases que alimentan la capa recurrente.\n",
        "\n",
        "![](https://i.imgur.com/1152PYf.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:43:51.447608Z",
          "start_time": "2020-09-04T13:43:51.433585Z"
        },
        "id": "x2ljo7vMDhIF"
      },
      "source": [
        "class AttnDecoder(torch.nn.Module):\n",
        "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
        "        self.out = torch.nn.Linear(hidden_size, input_size)\n",
        "\n",
        "        # attention\n",
        "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
        "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_words, hidden, encoder_outputs):\n",
        "        # sacamos los embeddings\n",
        "        embedded = self.embedding(input_words)\n",
        "        # calculamos los pesos de la capa de atenci√≥n\n",
        "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
        "        # re-escalamos los outputs del encoder con estos pesos\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
        "        # aplicamos la capa de atenci√≥n\n",
        "        output = self.attn_combine(output)\n",
        "        output = torch.nn.functional.relu(output)\n",
        "        # a partir de aqu√≠, como siempre. La diferencia es que la entrada a la RNN\n",
        "        # no es directmanete el embedding sino una combinaci√≥n del embedding\n",
        "        # y las salidas del encoder re-escaladas\n",
        "        output, hidden = self.gru(output.unsqueeze(1), hidden)\n",
        "        output = self.out(output.squeeze(1))\n",
        "        return output, hidden, attn_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.539231Z",
          "start_time": "2020-09-04T12:32:01.484236Z"
        },
        "id": "cXAw3xHpDhIF",
        "outputId": "a1837068-9111-4b8b-e7db-a633849207f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder = AttnDecoder(input_size=output_lang.n_words)\n",
        "decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, output_lang.n_words, (64, 1)), encoder_hidden, encoder_outputs)\n",
        "\n",
        "# [batch size, vocab size]\n",
        "decoder_output.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-51f795b71400>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 19777])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.547232Z",
          "start_time": "2020-09-04T12:32:01.541233Z"
        },
        "id": "JwlFc-8zDhIG",
        "outputId": "154d9355-5c22-4c8a-dc10-ea98bad2e37f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "decoder_hidden.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.572231Z",
          "start_time": "2020-09-04T12:32:01.548231Z"
        },
        "id": "ig9fzbH0DhIG",
        "outputId": "63ae657c-d7d6-4578-f62f-c87c6bf39ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [num layers, batch size, hidden size]\n",
        "decoder_hidden.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.578233Z",
          "start_time": "2020-09-04T12:32:01.573232Z"
        },
        "id": "FW_BF-feDhIG",
        "outputId": "b6b1977c-31b6-4754-c49e-826b20eb65a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [batch size, max_length]\n",
        "attn_weights.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfgvaCeWDhIG"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypR81P5sDhIG"
      },
      "source": [
        "Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generar√° la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:32:01.593231Z",
          "start_time": "2020-09-04T12:32:01.579232Z"
        },
        "code_folding": [
          3
        ],
        "id": "QDu8VoLqDhIG"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(encoder, decoder, dataloader, epochs=10):\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            input_sentences, output_sentences = batch\n",
        "            bs = input_sentences.shape[0]\n",
        "            loss = 0\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            # obtenemos el √∫ltimo estado oculto del encoder\n",
        "            encoder_outputs, hidden = encoder(input_sentences)\n",
        "            # calculamos las salidas del decoder de manera recurrente\n",
        "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "            for i in range(output_sentences.shape[1]):\n",
        "                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                loss += criterion(output, output_sentences[:, i].view(bs))\n",
        "                # el siguiente input ser√° la palabra predicha\n",
        "                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "            # optimizaci√≥n\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
        "\n",
        "        val_loss = []\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            bar = tqdm(dataloader['test'])\n",
        "            for batch in bar:\n",
        "                input_sentences, output_sentences = batch\n",
        "                bs = input_sentences.shape[0]\n",
        "                loss = 0\n",
        "                # obtenemos el √∫ltimo estado oculto del encoder\n",
        "                encoder_outputs, hidden = encoder(input_sentences)\n",
        "                # calculamos las salidas del decoder de manera recurrente\n",
        "                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
        "                for i in range(output_sentences.shape[1]):\n",
        "                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "                    loss += criterion(output, output_sentences[:, i].view(bs))\n",
        "                    # el siguiente input ser√° la palabra predicha\n",
        "                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
        "                val_loss.append(loss.item())\n",
        "                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T12:58:02.367102Z",
          "start_time": "2020-09-04T12:32:01.595236Z"
        },
        "id": "bwNeQeLGDhIH",
        "outputId": "9ea4ae62-95a5-41b4-a729-400d8dd1faa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fit(encoder, decoder, dataloader, epochs=30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1802 [00:00<?, ?it/s]<ipython-input-17-51f795b71400>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
            "Epoch 1/30 loss 29.57289: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:05<00:00, 27.54it/s]\n",
            "Epoch 1/30 val_loss 33.57932: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.55it/s]\n",
            "Epoch 2/30 loss 22.00338: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:00<00:00, 29.64it/s]\n",
            "Epoch 2/30 val_loss 30.21193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 18.92it/s]\n",
            "Epoch 3/30 loss 19.06302: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.28it/s]\n",
            "Epoch 3/30 val_loss 28.51631: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.70it/s]\n",
            "Epoch 4/30 loss 17.04084: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.47it/s]\n",
            "Epoch 4/30 val_loss 27.50327: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 18.85it/s]\n",
            "Epoch 5/30 loss 15.50890: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:00<00:00, 29.89it/s]\n",
            "Epoch 5/30 val_loss 27.01757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.33it/s]\n",
            "Epoch 6/30 loss 14.28816: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.46it/s]\n",
            "Epoch 6/30 val_loss 26.46044: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.10it/s]\n",
            "Epoch 7/30 loss 13.29801: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.33it/s]\n",
            "Epoch 7/30 val_loss 26.25013: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.65it/s]\n",
            "Epoch 8/30 loss 12.47428: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.16it/s]\n",
            "Epoch 8/30 val_loss 26.42706: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 17.76it/s]\n",
            "Epoch 9/30 loss 11.78772: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.54it/s]\n",
            "Epoch 9/30 val_loss 26.23944: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.08it/s]\n",
            "Epoch 10/30 loss 11.20713: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.29it/s]\n",
            "Epoch 10/30 val_loss 26.32332: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.25it/s]\n",
            "Epoch 11/30 loss 10.70164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.37it/s]\n",
            "Epoch 11/30 val_loss 26.27007: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.65it/s]\n",
            "Epoch 12/30 loss 10.26115: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.23it/s]\n",
            "Epoch 12/30 val_loss 26.39626: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.14it/s]\n",
            "Epoch 13/30 loss 9.88841: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.33it/s]\n",
            "Epoch 13/30 val_loss 26.66274: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.29it/s]\n",
            "Epoch 14/30 loss 9.54014: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.42it/s]\n",
            "Epoch 14/30 val_loss 26.70865: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 17.98it/s]\n",
            "Epoch 15/30 loss 9.25716: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.30it/s]\n",
            "Epoch 15/30 val_loss 26.85067: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.71it/s]\n",
            "Epoch 16/30 loss 8.99365: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.60it/s]\n",
            "Epoch 16/30 val_loss 26.99171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.44it/s]\n",
            "Epoch 17/30 loss 8.74770: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.13it/s]\n",
            "Epoch 17/30 val_loss 27.16559: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 19.03it/s]\n",
            "Epoch 18/30 loss 8.53269: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 29.04it/s]\n",
            "Epoch 18/30 val_loss 27.41554: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.79it/s]\n",
            "Epoch 19/30 loss 8.33758: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.98it/s]\n",
            "Epoch 19/30 val_loss 27.46677: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.17it/s]\n",
            "Epoch 20/30 loss 8.16625: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.72it/s]\n",
            "Epoch 20/30 val_loss 27.57856: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 18.92it/s]\n",
            "Epoch 21/30 loss 7.99354: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.34it/s]\n",
            "Epoch 21/30 val_loss 27.81768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.21it/s]\n",
            "Epoch 22/30 loss 7.85328: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.20it/s]\n",
            "Epoch 22/30 val_loss 28.03078: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.30it/s]\n",
            "Epoch 23/30 loss 7.71370: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.31it/s]\n",
            "Epoch 23/30 val_loss 28.02169: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.65it/s]\n",
            "Epoch 24/30 loss 7.58069: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.08it/s]\n",
            "Epoch 24/30 val_loss 28.55147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.30it/s]\n",
            "Epoch 25/30 loss 7.46012: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.45it/s]\n",
            "Epoch 25/30 val_loss 28.39905: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 21.32it/s]\n",
            "Epoch 26/30 loss 7.35283: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.33it/s]\n",
            "Epoch 26/30 val_loss 28.72973: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 17.57it/s]\n",
            "Epoch 27/30 loss 7.24591: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.80it/s]\n",
            "Epoch 27/30 val_loss 28.92229: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.61it/s]\n",
            "Epoch 28/30 loss 7.14513: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.76it/s]\n",
            "Epoch 28/30 val_loss 28.95803: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 19.68it/s]\n",
            "Epoch 29/30 loss 7.05258: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:02<00:00, 28.93it/s]\n",
            "Epoch 29/30 val_loss 29.12182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:06<00:00, 18.45it/s]\n",
            "Epoch 30/30 loss 6.95362: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1802/1802 [01:01<00:00, 29.16it/s]\n",
            "Epoch 30/30 val_loss 29.44561: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113/113 [00:05<00:00, 20.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81pQZ8FODhIH"
      },
      "source": [
        "## Generando traducciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpf0z3bbDhIH"
      },
      "source": [
        "Una vez tenemos nuestro modelo entrenado, podemos utilizarlo para traducir frases del ingles a aleman de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:31.925887Z",
          "start_time": "2020-09-04T13:12:31.915888Z"
        },
        "id": "zcFY7vzDDhIH",
        "outputId": "5c234e38-3aec-4875-ac95-bd823bea9977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_sentence, output_sentence = dataset['train'][100]\n",
        "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['no', 'way', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
              " ['das', 'kommt', 'nicht', 'in', 'frage', '!', 'EOS', 'PAD', 'PAD', 'PAD'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.615887Z",
          "start_time": "2020-09-04T13:12:32.598887Z"
        },
        "code_folding": [],
        "id": "RzxhNLU8DhIH"
      },
      "source": [
        "def predict(input_sentence):\n",
        "    # obtenemos el √∫ltimo estado oculto del encoder\n",
        "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
        "    # calculamos las salidas del decoder de manera recurrente\n",
        "    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
        "    # iteramos hasta que el decoder nos de el token <eos>\n",
        "    outputs = []\n",
        "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
        "    i = 0\n",
        "    while True:\n",
        "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
        "\n",
        "        if i < MAX_LENGTH:\n",
        "            decoder_attentions[i] = attn_weights.data\n",
        "        else:\n",
        "            break\n",
        "        i += 1\n",
        "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
        "        outputs.append(decoder_input.cpu().item())\n",
        "        if decoder_input.item() == output_lang.word2index['EOS']:\n",
        "            break\n",
        "    return output_lang.sentenceFromIndex(outputs), decoder_attentions"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:32.789887Z",
          "start_time": "2020-09-04T13:12:32.775888Z"
        },
        "id": "nJWDsiGsDhII",
        "outputId": "3c393034-3d19-4215-d09d-5fd57f441210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output_words, attn = predict(input_sentence)\n",
        "output_words"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-51f795b71400>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kein', 'ist', '!', '!', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'EOS']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVk45xViDhII"
      },
      "source": [
        "## Visualizaci√≥n de atenci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIwB1jkSDhII"
      },
      "source": [
        "Una de las ventajas que nos da la capa de atenci√≥n es que nos permite visualizar en qu√© partes de los inputs se fija el modelo para generar cada una de las palabras en el output, dando un grado de explicabilidad a nuestro modelo (una propiedad siempre deseada en nuestro modelos de `Machine Learning`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:33.513889Z",
          "start_time": "2020-09-04T13:12:33.505889Z"
        },
        "id": "ZnOX1xXEDhII"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    lim1, lim2 = input_sentence.index('EOS')+1, output_words.index('EOS')+1\n",
        "    fig = plt.figure(dpi=100)\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
        "    ax.set_yticklabels([' '] + output_words)\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-04T13:12:34.273921Z",
          "start_time": "2020-09-04T13:12:34.160888Z"
        },
        "id": "vchBo16ODhII",
        "outputId": "e232f42d-3824-4a9c-bac4-a7d05494e1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-c3618fc79f44>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
            "<ipython-input-37-c3618fc79f44>:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([' '] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0Bx95ZDhII"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozvpo0sfDhII"
      },
      "source": [
        "En este post hemos visto como introducir mecanismos de atenci√≥n en nuestra arquitectura `encoder-decoder`, los cuales permiten a nuestra red neuronal focalizarse en partes concretas de los *inputs* a la hora de generar los *outputs*. Esta nueva capa no solo puede mejorar nuestros modelos sino que adem√°s tambi√©n es interpretable, d√°ndonos una idea del razonamiento detr√°s de las predicciones de nuestro modelo. Las redes neuronales con mejores prestaciones a d√≠a de hoy en tareas de `NLP`, los `transformers`, est√°n basados enteramente en este tipo de capas de atenci√≥n."
      ]
    }
  ]
}