# -*- coding: utf-8 -*-
"""Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lF0FJOT_7JveDwUT4XtuoJ8LrpH7-yiI
"""

#importamos los datos necesarios
#dataset escogido = https://www.kaggle.com/datasets/gpiosenka/70-dog-breedsimage-data-set?select=test

#conectamos a drive
from google.colab import drive
drive.mount('/content/drive')

import torch

#descomprimir el zip
ruta_del_archivo ="/content/drive/MyDrive/datasets/dataset_perros.zip"
ruta_de_destino= "/content"
!unzip '/content/drive/MyDrive/datasets/dataset_perros.zip' -d '/content/dataset'
!unzip '/content/drive/MyDrive/datasets/dataset_perros.zip' -d '/content'

import pandas as pd
from torchvision.datasets import CIFAR10
from torchvision import transforms
from PIL import Image
import os

# Cargar el CSV que contiene las rutas de las imágenes y sus etiquetas
ruta_csv = "/content/dogs.csv"
datos_csv = pd.read_csv(ruta_csv)

# Define la transformación para redimensionar las imágenes a 32x32 píxeles
transformacion = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor()
])

# Lista para almacenar las imágenes y etiquetas
imagenes = []
etiquetas = []

# Iterar sobre las filas del CSV para cargar las imágenes y etiquetas
for indice, fila in datos_csv.iterrows():
    ruta_imagen = fila['filepaths']  # Suponiendo que la columna con las rutas de las imágenes se llama 'ruta_imagen'
    etiqueta = fila['labels']  # Suponiendo que la columna con las etiquetas se llama 'etiqueta'

    # Abrir la imagen y aplicar la transformación
    imagen = Image.open(ruta_imagen)
    imagen_transformada = transformacion(imagen)

    # Agregar la imagen y etiqueta a las listas
    imagenes.append(imagen_transformada)
    etiquetas.append(etiqueta)

# Crea el conjunto de datos CIFAR-10 personalizado
cifar10_personalizado = [(imagen, etiqueta) for imagen, etiqueta in zip(imagenes, etiquetas)]

# Ahora puedes usar este conjunto de datos personalizado

# Divide el conjunto de datos en conjuntos de entrenamiento y prueba (80% train, 20% test)
n_datos = len(cifar10_personalizado)
n_train = int(0.8 * n_datos)
n_test = n_datos - n_train
trainset, testset = torch.utils.data.random_split(cifar10_personalizado, [n_train, n_test])

# Ahora puedes utilizar train_set y test_set para entrenar y probar tu modelo

import pandas as pd
df = pd.read_csv("/content/dataset/dogs.csv",sep=",")
mask_train=df['data set'] == "train"
mask_train=df['data set'] == "test"
df[mask_train]

import random
import matplotlib.pyplot as plt

# Definir el número de filas y columnas para mostrar las imágenes
r, c = 3, 5

# Obtener una muestra aleatoria de índices del conjunto de entrenamiento
indices = random.sample(range(len(trainset)), r*c)

# Crear una figura para mostrar las imágenes
plt.figure(figsize=(c*3, r*3))

# Iterar sobre las filas y columnas para mostrar las imágenes
for row in range(r):
    for col in range(c):
        index = c*row + col
        plt.subplot(r, c, index + 1)

        # Obtener la imagen y la etiqueta correspondiente para el índice actual
        img, label = trainset[indices[index]]

        # Mostrar la imagen y configurar los ejes
        plt.imshow(img.permute(1, 2, 0))  # La imagen se convierte de (C, H, W) a (H, W, C) para que matplotlib pueda mostrarla correctamente
        plt.axis('off')
        plt.title(f'Label: {label}')  # Mostrar la etiqueta como título

# Ajustar el espacio entre las imágenes en la figura
plt.subplots_adjust(wspace=0.2, hspace=0.5)

# Mostrar la figura con las imágenes
plt.show()

# convertimos imágenes a arrays de numpy

import numpy as np

train_images = np.array([np.array(img) for img, label in trainset])
test_images = np.array([np.array(img) for img, label in testset])

train_labels = np.array([label for img, label in trainset])
test_labels = np.array([label for img, label in testset])

# ver número de imágenes, resolución y número de canales

train_images.shape, test_images.shape, train_labels.shape, test_labels.shape

# tipo de datos

train_images.dtype, train_labels.dtype

# estadísiticos

max_value = train_images.max(axis=(0, 1, 2))
min_value = train_images.min(axis=(0, 1, 2))

max_value, min_value

mean = (train_images / 255).mean(axis=(0, 1, 2))
std = (train_images / 255).std(axis=(0, 1, 2))

mean, std

# distribución de clases

plt.hist(train_labels[:30000], bins=len(etiquetas))
plt.show()

unique, counts = np.unique(train_labels, return_counts=True)
unique, counts

import torch

def build_model(D_in=32*32*3, H=100, D_out=10):
    return torch.nn.Sequential(
        torch.nn.Linear(D_in, H),
        torch.nn.ReLU(),
        torch.nn.Linear(H, H),
        torch.nn.ReLU(),
        torch.nn.Linear(H, D_out)
    ).cuda()

model = build_model()
test_input = torch.randn((64, 32*32*3)).cuda()
test_output = model(test_input)
test_output.shape

import numpy as np

train_images = np.array([np.array(img) for img, label in trainset])
X_test = np.array([np.array(img) for img, label in testset])

train_labels = np.array([label for img, label in trainset])
y_test = np.array([label for img, label in testset])

X_train, X_val, X_subset = train_images[:40000], train_images[40000:], train_images[:5000]
y_train, y_val, y_subset = train_labels[:40000], train_labels[40000:], train_labels[:5000]

X_train.shape, X_val.shape, X_test.shape, X_subset.shape

class Dataset(torch.utils.data.Dataset):
    def __init__(self, X, Y):
        self.X = torch.from_numpy(X / 255.).float().cuda().view(-1, 32*32*3)
        self.Y = torch.from_numpy(Y).long().cuda()
    def __len__(self):
        return len(self.X)
    def __getitem__(self, ix):
        return self.X[ix], self.Y[ix]

from sklearn.preprocessing import LabelEncoder

# Convertir las etiquetas a números enteros utilizando LabelEncoder
encoder = LabelEncoder()
y_subset_numeric = encoder.fit_transform(y_subset)

# Crear el conjunto de datos con las etiquetas numéricas
dataset = Dataset(X_subset[:1], y_subset_numeric[:1])

# Crear el dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)

# Comprobar la longitud del dataset
print(len(dataset))


dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)

len(dataset)

epochs = 5
criterion = torch.nn.CrossEntropyLoss()
model = build_model()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
for e in range(1, epochs+1):
    for x_b, y_b in dataloader:
        y_pred = model(x_b)
        loss = criterion(y_pred, y_b)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print(f"Epoch {e}/{epochs} loss {loss.item():.5f} y {y_b.item()} y_pred {torch.argmax(y_pred, axis=1).item()}")