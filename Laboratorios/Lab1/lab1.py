# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xv4eCKF0WiNMWiQeKl_UfWrbo1ypVz_X
"""

#!pip install onnx

# Commented out IPython magic to ensure Python compatibility.
#paquetes
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'
import helper
import matplotlib.pyplot as plt

import numpy as np
import torch
from torchvision import datasets,transforms

import pandas as pd

#preparacion de datos
df= pd.read_csv('/content/sensor_readings_24.csv', header=None)

df

df[24] = pd.Categorical(df[24]).codes

df

from sklearn.preprocessing import MinMaxScaler

#para normalizar los datos
scaler = MinMaxScaler()

# Selecciona las columnas que deseas normalizar
columnas_a_normalizar = df.columns  # Puedes seleccionar las columnas que desees

columnas_a_normalizar=columnas_a_normalizar.drop(24)

# Normaliza los datos
df[columnas_a_normalizar] = scaler.fit_transform(df[columnas_a_normalizar])

df[24].nunique()

#importamos los modulos necesarios
from torch import nn
import torch.nn.functional as F

#creamos la red
class RedNeuronal(nn.Module):
  def __init__(self):
    super().__init__()
    # definimos metodos lineales
    ## 24 > 20 > 15 > 10 > 5 > 3 softmax
    self.fc1 = nn.Linear(24,20)
    self.fc2 = nn.Linear(20,15)
    self.fc3 = nn.Linear(15,10)
    self.fc4 = nn.Linear(10,5)
    self.fc5 = nn.Linear(5,4)
  def forward(self,x):
    #Funcion que realiza la operacion de pase frontal y obtiene las probabilidades
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    x = F.relu(x)
    x = self.fc4(x)
    x = F.relu(x)
    x = self.fc5(x)
    x = F.softmax(x,dim=1)


    return x

#instanciamos la red
model = RedNeuronal()
print(model)

#llenamos de 0
model.fc1.bias.data.fill_(0)

#inicializamos los pesos con desviacion estandar
model.fc1.weight.data.normal_(std=0.01)

#comvertimos los datos a tensores


# Convierte el DataFrame a un arreglo de NumPy
array = df.values

# Convierte el arreglo de NumPy a un tensor de PyTorch
tensor = torch.tensor(array)

# Muestra el tensor resultante
print(tensor)

#separamos los datos de entrenamiento con los de prueba

train_size = int(0.8 * tensor.size(0))

# Divide el tensor en datos de entrenamiento y datos de prueba
datos_entrenamiento, datos_prueba = torch.split(tensor, [train_size, tensor.size(0) - train_size])

# Muestra los tamaños de los datos de entrenamiento y prueba
print("Tamaño de los datos de entrenamiento:", datos_entrenamiento.size(0))
print("Tamaño de los datos de prueba:", datos_prueba.size(0))

#separamos datos de los resultados(test)
# Obtiene todas las filas y todas las columnas excepto la última (datos de entrada)
datosTest = datos_prueba[:, :-1]

# Obtiene todas las filas y la última columna (resultados)
etiquetasTest = datos_prueba[:, -1]

# Muestra los datos de entrada y los resultados
print("Datos de entrada:")
print(datos_prueba)
print("\nResultados:")
print(etiquetasTest)

#separamos datos de los resultados
# Obtiene todas las filas y todas las columnas excepto la última (datos de entrada)
datos_entrada = datos_entrenamiento[:, :-1]

# Obtiene todas las filas y la última columna (resultados)
etiquetas = datos_entrenamiento[:, -1]

# Muestra los datos de entrada y los resultados
print("Datos de entrada:")
print(datos_entrada)
print("\nResultados:")
print(etiquetas)

import torch.nn as nn
import torch.optim as optim

import torch.onnx as onnx
from torch.utils.data import DataLoader, Dataset
import torchvision.models as models
import os

# Supongamos que tienes un modelo llamado 'modelo' y quieres guardar checkpoints cada 20 épocas

# Definir el nombre del carpeta donde se guardarán los checkpoints
checkpoint_folder = "checkpoints2/"
# Crear el directorio si no existe
if not os.path.exists(checkpoint_folder):
    os.makedirs(checkpoint_folder)

# Define tu función de pérdida
criterio = nn.CrossEntropyLoss()

# Define tu optimizador
red_neuronal = model
optimizador = optim.Adam(red_neuronal.parameters(), lr=0.001)

# Supongamos que `datos_entrada` y `etiquetas` son tus datos de entrenamiento
for epoch in range(1000):
    # Limpia los gradientes
    optimizador.zero_grad()

    datos_entrada = datos_entrada.to(torch.float)
    # Pase hacia adelante
    resultados = red_neuronal(datos_entrada)

    # Calcula la pérdida
    resultados = resultados.float()

    # Aplica softmax
    resultados_softmax = F.softmax(resultados, dim=1)
    etiquetas = etiquetas.long()
    perdida = criterio(resultados_softmax, etiquetas)

    # Retropropagación
    perdida.backward()

    # Actualiza los pesos
    optimizador.step()

    # Muestra la pérdida
    print('Época [{}/{}], Pérdida: {:.4f}'.format(epoch+1, 1000, perdida.item()))

    # Guardar checkpoint cada 20 épocas
    if (epoch + 1) % 20 == 0:

      checkpoint_path = f"{checkpoint_folder}modelo_epoch_{epoch+1}.pth"
      torch.save({
          'epoch': epoch,
          'model_state_dict': model.state_dict(),
          # Agrega otros elementos que desees guardar
      }, checkpoint_path)

# Convertir el modelo a ONNX
dummy_input = torch.randn(1, 24)  # Input de ejemplo
onnx_path = "modelo.onnx"
torch.onnx.export(model, dummy_input, onnx_path)

# Cambia la red neuronal al modo de evaluación
red_neuronal.eval()

# No necesitamos calcular gradientes durante el test
with torch.no_grad():
    # Pase hacia adelante con los datos de test

    datosTest = datosTest.to(torch.float)
    resultados_test = red_neuronal(datosTest)

    # Calcula las predicciones
    _, predicciones = torch.max(resultados_test, 1)  # Obtiene la clase predicha para cada ejemplo

    # Calcula la precisión
    correctas = (predicciones == etiquetasTest).sum().item()
    total = etiquetasTest.size(0)
    precision = correctas / total
    print('Precisión en el conjunto de test: {:.2f}%'.format(precision * 100))